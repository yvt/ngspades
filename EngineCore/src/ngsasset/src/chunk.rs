//
// Copyright 2019 yvt, all rights reserved.
//
// This source code is a part of Nightingales.
//
//! The reader and writer of the standard chunk format.
use azure_functions_shared_codegen::generated_mod;
use flatbuffers::FlatBufferBuilder;
use std::{
    borrow::Borrow,
    cmp::max,
    collections::HashMap,
    io::{self, prelude::*, SeekFrom},
    ops::Range,
};
use uuid::Uuid;

use crate::utils::{HashableUuid, ReadWindow};

const BLOB_ALIGN: usize = 16;

/// The code for Flatbuffer schema definition generated by `build.rs`.
///
/// `#[generated_mod]` is a work-around for
/// <https://github.com/rust-lang/rfcs/issues/752> (include! macro fails if
/// included file has top-level inner attributes).
generated_mod!(chunk_generated);

/// A reader for a chunk's content part, constructed by [`chunk_reader`].
#[derive(Debug, Clone, Copy)]
pub struct ChunkDataReader<R> {
    reader: R,
    data_offset: u64,
}

/// Construct a `ChunkDataReader` and `Vec<u8>` (containing the chunk header
/// that can be read by [`chunk_hdr_get_blob_range`]) from a readable stream.
///
/// `reader`'s cursor is moved to the start of the blob data. You can get the
/// original `reader` by calling [`ChunkDataReader::into_inner`].
pub fn chunk_reader<R: Read + Seek>(
    mut reader: R,
) -> Result<(ChunkDataReader<R>, Vec<u8>), ChunkError> {
    // Read the header
    let hdr_len = {
        let mut bytes = [0; 4];
        reader.read_exact(&mut bytes)?;
        <u32>::from_le_bytes(bytes)
    };

    let mut header = vec![0; hdr_len as usize - 4];
    reader.read_exact(&mut header[..])?;

    let data_offset = reader.seek(io::SeekFrom::Current(0))?;
    let data = ChunkDataReader {
        reader,
        data_offset,
    };

    Ok((data, header))
}

impl<R: Read + Seek> ChunkDataReader<R> {
    /// Construct a reader for a blob.
    ///
    /// `range` is the position of the blob data to be read. You can use
    /// [`chunk_hdr_get_blob_range`] to retrieve one from the chunk header.
    pub fn read_blob(&mut self, range: &Range<u64>) -> io::Result<BlobDataReader<&mut R>> {
        let data_offset = self.data_offset;
        Ok(ReadWindow::new(
            &mut self.reader,
            range.start + data_offset..range.end + data_offset,
        )?)
    }
}

impl<R> ChunkDataReader<R> {
    /// Get the original writer without finalizing the metadata.
    pub fn into_inner(self) -> R {
        self.reader
    }

    /// Get the origin of the blob data.
    pub fn data_start(&self) -> u64 {
        self.data_offset
    }
}

/// A reader for blob data, constructed by [`ChunkDataReader::read_blob`].
pub type BlobDataReader<R> = ReadWindow<R>;

/// Enumerate the blobs in a chuck header.
pub fn chunk_hdr_get_blobs<'a>(
    hdr: &'a [u8],
) -> Result<impl Iterator<Item = Uuid> + 'a, ChunkError> {
    use chunk_generated as fbs;
    let chunk_hdr = fbs::get_root_as_chunk_hdr(hdr);
    let blobs = chunk_hdr.blobs();

    Ok((0..blobs.len()).filter_map(move |i| {
        let blobs = chunk_hdr.blobs();
        blobs
            .get(i)
            .id()
            .and_then(|bytes| Uuid::from_slice(bytes).ok())
    }))
}

/// Find the position (relative to the end of the header) of the blob data for
/// a given blob ID in a chunk header.
pub fn chunk_hdr_get_blob_range(
    hdr: &[u8],
    blob_id: Uuid,
) -> Result<Option<Range<u64>>, ChunkError> {
    use chunk_generated as fbs;
    let chunk_hdr = fbs::get_root_as_chunk_hdr(hdr);
    let blobs = chunk_hdr.blobs();

    let blob = if let Some(phf_map) = chunk_hdr.blob_map_as_phf_map() {
        // Use the hashtable
        let hash = phf_shared::hash(&HashableUuid(blob_id), phf_map.key());
        let (g, f1, f2) = phf_shared::split(hash);
        let disps = phf_map.disps();
        let disp = disps[(g % (disps.len() as u32)) as usize];
        let i = phf_shared::displace(f1, f2, disp.disp1(), disp.disp2()) % (blobs.len() as u32);

        let blob = blobs.get(i as usize);
        if blob.id() == Some(&blob_id.as_bytes()[..]) {
            Some(blob)
        } else {
            None
        }
    } else {
        // Linear search
        let mut i = 0;
        loop {
            if i >= blobs.len() {
                break None;
            } else if blobs.get(i).id() == Some(&blob_id.as_bytes()[..]) {
                break Some(blobs.get(i));
            } else {
                i += 1;
            }
        }
    };

    Ok(blob.map(|blob| blob.offset()..blob.offset() + blob.len()))
}

/// A reader for a chunk haeder.
#[derive(Debug)]
pub struct ChunkHdrReader<T>(pub T);

impl<T: Borrow<[u8]>> ChunkHdrReader<T> {
    /// Find the position (relative to the end of the header) of the blob data
    /// for a given blob ID in a chunk header.
    ///
    /// This method is an ergonomic wrapper of [`chunk_hdr_get_blob_range`].
    pub fn get_blob_range(&self, blob_id: Uuid) -> Result<Option<Range<u64>>, ChunkError> {
        chunk_hdr_get_blob_range(self.0.borrow(), blob_id)
    }

    /// Enumerate the blobs in a chuck header.
    pub fn get_blobs<'a>(&'a self) -> Result<impl Iterator<Item = Uuid> + 'a, ChunkError> {
        chunk_hdr_get_blobs(self.0.borrow())
    }
}

/// The error type for a chunk reading opertaion.
#[derive(Debug)]
pub enum ChunkError {
    /// The data format is invalid.
    ///
    /// FIXME: This variant is actually not used.
    Malformed(&'static str),
    /// An I/O error occurred in the wrapped reader.
    IoError(io::Error),
}

impl From<io::Error> for ChunkError {
    fn from(x: io::Error) -> Self {
        ChunkError::IoError(x)
    }
}

impl From<ChunkError> for io::Error {
    fn from(x: ChunkError) -> Self {
        match x {
            ChunkError::Malformed(_) => io::Error::new(io::ErrorKind::Other, Box::new(x)),
            ChunkError::IoError(e) => e,
        }
    }
}

impl std::error::Error for ChunkError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match self {
            ChunkError::Malformed(_) => None,
            ChunkError::IoError(e) => Some(e),
        }
    }
}

impl std::fmt::Display for ChunkError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            ChunkError::Malformed(x) => write!(f, "Malformed: {}", x),
            ChunkError::IoError(e) => e.fmt(f),
        }
    }
}

/// Writes chunk data to a writer in the standard chunk format.
pub struct ChunkWriter<W> {
    writer: W,
    hash_state: phf_generator::HashState,
    blobs: HashMap<Uuid, Option<BlobMeta>>,
    hdr_offset: u64,
    hdr_len: usize,
    data_offset: u64,
}

/// The metadata of a blob within a chunk.
#[derive(Debug, Clone, Copy, Default)]
pub struct BlobMeta {
    /// The blob data's position relative to the header's ending position.
    offset: u64,
    /// The length of the blob data.
    len: u64,
}

impl<W: Write + Seek> ChunkWriter<W> {
    /// Construct a `ChunkWriter`.
    ///
    /// `blob_ids` specifies the set of blob IDs to be included in the generated
    /// chunk.
    pub fn new(mut writer: W, blob_ids: impl Iterator<Item = Uuid>) -> io::Result<Self> {
        let uuids: Vec<_> = blob_ids.map(HashableUuid).collect();
        let hash_state = phf_generator::generate_hash(&uuids);

        let blobs: HashMap<Uuid, Option<BlobMeta>> = uuids.iter().map(|x| (x.0, None)).collect();

        // Pre-allocate the region for storing the metadata
        let mut fb_builder = FlatBufferBuilder::new();

        let mut hdr_len = fb_build_chunk(&mut fb_builder, &hash_state, &blobs, true).len();
        hdr_len = (hdr_len + 4 + (BLOB_ALIGN - 1)) & !(BLOB_ALIGN - 1);
        let hdr_offset = writer.seek(SeekFrom::Current(0))?;
        let data_offset = hdr_offset + hdr_len as u64;
        writer.seek(SeekFrom::Start(data_offset))?;

        Ok(Self {
            writer,
            hash_state,
            blobs: uuids.iter().map(|x| (x.0, None)).collect(),
            hdr_offset,
            hdr_len,
            data_offset,
        })
    }

    /// Start writing the contents of a blob.
    ///
    /// Panics if `id` is not a member of `blob_ids` provided to the `new`
    /// function or `id` has already been written by a previous call to
    /// `write_blob`.
    ///
    /// You must call `BlobWriter::finish` after writing the contents.
    pub fn write_blob(&mut self, id: Uuid) -> io::Result<BlobWriter<W>> {
        match self.blobs.get(&id) {
            Some(&None) => {}
            Some(&Some(_)) => panic!("cannot write a blob {:?} twice", id),
            None => panic!("{:?} is not in blob_ids", id),
        }

        let offset = self.writer.seek(SeekFrom::Current(0))?;

        Ok(BlobWriter {
            chunk_writer: self,
            id,
            offset,
            len: 0,
            cursor: 0,
        })
    }

    /// Finalize the metadata and return the original writer.
    pub fn finish(self) -> Result<W, (W, io::Error)> {
        let mut writer = self.writer;

        // Save the original cursor position
        let end = match writer.seek(SeekFrom::Current(0)) {
            Ok(x) => x,
            Err(x) => return Err((writer, x)),
        };

        // Serialize the metadata
        let mut fb_builder = FlatBufferBuilder::new_with_capacity(self.hdr_len);
        let hdr = fb_build_chunk(&mut fb_builder, &self.hash_state, &self.blobs, false);
        assert!(hdr.len() <= self.hdr_len - 4);

        if let Err(x) = writer.seek(SeekFrom::Start(self.hdr_offset)) {
            return Err((writer, x));
        }
        if let Err(x) = writer.write_all(&(self.hdr_len as u32).to_le_bytes()[..]) {
            return Err((writer, x));
        }
        if let Err(x) = writer.write_all(hdr) {
            return Err((writer, x));
        }

        // Restore the cursor position
        if let Err(x) = writer.seek(SeekFrom::Start(end)) {
            return Err((writer, x));
        }

        Ok(writer)
    }
}

impl<W> ChunkWriter<W> {
    /// Get the original writer without finalizing the metadata.
    pub fn into_inner(self) -> W {
        self.writer
    }
}

/// A writer for blob data, constructed by [`ChunkWriter::write_blob`].
pub struct BlobWriter<'a, W> {
    chunk_writer: &'a mut ChunkWriter<W>,
    id: Uuid,
    offset: u64,
    len: u64,
    cursor: u64,
}

impl<W: Write + Seek> BlobWriter<'_, W> {
    /// Finalize the metadata for the currently written blob.
    pub fn finish(mut self) -> io::Result<()> {
        *self.chunk_writer.blobs.get_mut(&self.id).unwrap() = Some(BlobMeta {
            offset: self.offset - self.chunk_writer.data_offset,
            len: self.len,
        });

        // Move the cursor to where the next blob is written
        self.len = (self.len + (BLOB_ALIGN as u64 - 1)) & !(BLOB_ALIGN as u64 - 1);
        self.seek(io::SeekFrom::End(0))?;

        Ok(())
    }
}

impl<W: Write + Seek> Seek for BlobWriter<'_, W> {
    fn seek(&mut self, pos: io::SeekFrom) -> io::Result<u64> {
        let pos = match pos {
            io::SeekFrom::Start(x) => x,
            io::SeekFrom::End(x) => (self.len as i64 + x) as u64,
            io::SeekFrom::Current(x) => (self.offset as i64 + x) as u64,
        };
        self.chunk_writer
            .writer
            .seek(io::SeekFrom::Start(self.offset + pos))?;
        self.cursor = pos;
        Ok(pos)
    }
}

impl<W: Write + Seek> Write for BlobWriter<'_, W> {
    fn write(&mut self, buf: &[u8]) -> io::Result<usize> {
        let bytes_written = self.chunk_writer.writer.write(buf)?;
        self.len = max(self.len, self.cursor + bytes_written as u64);
        self.cursor += bytes_written as u64;
        Ok(bytes_written)
    }
    fn flush(&mut self) -> io::Result<()> {
        self.chunk_writer.writer.flush()
    }
}

/// Serialize chunk metadata.
/// A finalized byte slice (returned by `FlatBufferBuilder::finished_data`)
/// will be returned.
///
/// If `dummy` is true, it will generate dummy data which is large
/// enough to contain any real data with similar contents.
fn fb_build_chunk<'a>(
    builder: &'a mut FlatBufferBuilder<'_>,
    hash_state: &phf_generator::HashState,
    blobs: &HashMap<Uuid, Option<BlobMeta>>,
    dummy: bool,
) -> &'a [u8] {
    use chunk_generated as fbs;

    builder.reset();

    let disps = {
        let disps = &hash_state.disps;
        builder.start_vector::<fbs::PhfDisp>(disps.len());
        for &(d1, d2) in disps {
            builder.push(fbs::PhfDisp::new(d1, d2));
        }
        builder.end_vector::<fbs::PhfDisp>(disps.len())
    };

    let phf_map = fbs::PhfMap::create(
        &mut *builder,
        &fbs::PhfMapArgs {
            key: hash_state.key,
            disps: Some(disps),
        },
    );

    let blobs = {
        let mut blob_offsets = vec![None; blobs.len()];
        for (id, meta) in blobs.iter() {
            let id_offset = if meta.is_some() || dummy {
                Some(builder.create_vector(&id.as_bytes()[..]))
            } else {
                None
            };
            let meta = if dummy {
                // Flatbuffers appears to do some kind of compression when
                // fields have default values, so fill them with random values
                BlobMeta {
                    offset: 0x1234567812345678,
                    len: 0x1234567812345678,
                }
            } else {
                meta.unwrap_or_default()
            };
            let offset = fbs::BlobMeta::create(
                &mut *builder,
                &fbs::BlobMetaArgs {
                    id: id_offset,
                    offset: meta.offset,
                    len: meta.len,
                },
            );

            // Find the bucket
            let hash = phf_shared::hash(&HashableUuid(*id), hash_state.key);
            let index = phf_shared::get_index(hash, &hash_state.disps, blob_offsets.len());

            let entry = &mut blob_offsets[index as usize];
            assert!(entry.is_none(), "found a hash collision");
            *entry = Some(offset);
        }

        let blob_offsets2: Vec<_> = blob_offsets.into_iter().map(|x| x.unwrap()).collect();
        builder.create_vector(&blob_offsets2)
    };

    let chunk_meta = fbs::ChunkHdr::create(
        &mut *builder,
        &fbs::ChunkHdrArgs {
            blob_map_type: fbs::BlobMap::PhfMap,
            blob_map: Some(phf_map.as_union_value()),
            blobs: Some(blobs),
        },
    );

    builder.finish(chunk_meta, None);

    builder.finished_data()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn chunk_twoway() {
        let mut chunk_data: Vec<u8> = Vec::new();

        let blobs = [
            Uuid::parse_str("8fd8b9f8-4d22-48a2-990e-1b7fc29db5a1").unwrap(),
            Uuid::parse_str("ad1c9a13-1e33-4a48-aeec-e4468bf2fc6c").unwrap(),
            Uuid::parse_str("78ea264f-36b3-4afe-b669-5ad4be0306cc").unwrap(),
            Uuid::parse_str("f171347e-969a-4348-af46-97277606496b").unwrap(),
        ];

        {
            let mut chunk_writer =
                ChunkWriter::new(io::Cursor::new(&mut chunk_data), blobs.iter().cloned()).unwrap();
            for &blob_id in blobs.iter() {
                let mut blob_writer = chunk_writer.write_blob(blob_id).unwrap();
                blob_writer.write_all(&blob_id.as_bytes()[..]).unwrap();
                blob_writer.finish().unwrap();
            }
            chunk_writer.finish().unwrap();
        }

        println!("Chunk = {:?}", &chunk_data);

        {
            let (mut chunk_reader, hdr) = chunk_reader(io::Cursor::new(&chunk_data[..])).unwrap();
            for &blob_id in blobs.iter().rev() {
                let blob_meta = chunk_hdr_get_blob_range(&hdr, blob_id).unwrap().unwrap();
                dbg!((blob_id, &blob_meta));
                let mut blob_reader = chunk_reader.read_blob(&blob_meta).unwrap();
                let mut buf = Vec::new();
                blob_reader.read_to_end(&mut buf).unwrap();
                assert_eq!(&buf[..], &blob_id.as_bytes()[..]);
            }

            let alia_idtgilo = Uuid::parse_str("3f26e2cc-7450-4dc6-8e28-0b097c5b48fa").unwrap();
            assert!(chunk_hdr_get_blob_range(&hdr, alia_idtgilo)
                .unwrap()
                .is_none());
        }
    }
}
